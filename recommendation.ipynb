{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Mapping dictionary has been generated when processing raw data\n",
    "\n",
    "We just need to use the dictionary to transform validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict(file_path):\n",
    "    '''read id mapping into dictionary\n",
    "    '''\n",
    "    d = {}\n",
    "    with open(file_path) as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "           (key, val) = line.strip('\\n').split(',')\n",
    "           d[int(key)] = int(val)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = read_dict('./processed/user_dict.txt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dict = read_dict('./processed/movie_dict.txt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400267 users and 17375 movies\n"
     ]
    }
   ],
   "source": [
    "num_user = len(user_dict)\n",
    "num_movie = len(movie_dict)\n",
    "\n",
    "print('{} users and {} movies'.format(num_user, num_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'user_id': 'int32',\n",
    "          'movie_id': 'int16',\n",
    "          'rating': 'int8'}\n",
    "\n",
    "cols = ['user_id', 'movie_id', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('processed/netflix_train_encoded.csv', usecols=cols, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('processed/netflix_val.csv', usecols=cols, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['user_id'] = val['user_id'].map(user_dict)     # map user_id to continious index\n",
    "val['movie_id'] = val['movie_id'].map(movie_dict)  # map movie_id to continious index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove user and movie not seen in train\n",
    "val = val.loc[val['user_id'].notnull() & val['movie_id'].notnull()]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netflix_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = df['user_id'].values\n",
    "        self.movies = df['movie_id'].values\n",
    "        self.ratings = df['rating'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.users[idx], self.movies[idx], self.ratings[idx]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        # initlializing weights\n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        return (u*v).sum(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, train_dl, test_dl, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i, (users, items, ratings) in enumerate(train_dl):\n",
    "            #users = torch.LongTensor(users) #.cuda()\n",
    "            #items = torch.LongTensor(movies) #.cuda()\n",
    "            #ratings = torch.FloatTensor(ratings)  #.cuda()\n",
    "            \n",
    "            if unsqueeze:\n",
    "                ratings = ratings.unsqueeze(1)\n",
    "            y_hat = model.forward(users.long(), items.long())\n",
    "            loss = F.mse_loss(y_hat, ratings.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"[epoch {}] loss: {}\".format(epoch+1, loss.item())) # used to be loss.data[0]\n",
    "        \n",
    "    print(\"[test] loss: {}\".format(test_loss(model, test_dl, unsqueeze)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss(model, test_dl, unsqueeze=False):\n",
    "    model.eval()\n",
    "    #users, items, ratings = test\n",
    "    #users = torch.LongTensor(df_val.userId.values) # .cuda()\n",
    "    #items = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
    "    #ratings = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
    "    \n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    \n",
    "    for i, (users, items, ratings) in enumerate(test_dl):\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        \n",
    "        batch_size = ratings.shape[0]\n",
    "        y_hat = model(users.long(), items.long())\n",
    "        \n",
    "        batch_loss = F.mse_loss(y_hat, ratings.float()).item() * batch_size\n",
    "        sum_loss += batch_loss\n",
    "        total += batch_size\n",
    "        \n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Netflix_Dataset(train[:10000])\n",
    "valid_ds = Netflix_Dataset(val[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(num_user, num_movie, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 3.5486316680908203\n",
      "[test] loss: 7.437562992572785\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, train_dl, valid_dl, epochs=1, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
